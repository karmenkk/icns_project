{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jokes_embeddings_sbert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TC_CmTvpmLD",
        "outputId": "9b16fd15-fb45-4364-8736-46b9c094d5ac"
      },
      "source": [
        "!pip install -U sentence-transformers\r\n",
        "!pip install plotly==4.14.1\r\n",
        "!pip install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/9a/62beeb5501b70ab48b9e5bb92de290f00a661a1caa075c4aae56d452aaa0/sentence-transformers-0.4.0.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.4MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 14.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.7.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.19.4)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 53.2MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 56.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.8)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.8)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.4.0-cp36-none-any.whl size=102655 sha256=fd11bfbd5f1735a7ebc3a694a39381a668d77eb30cdf8eb95121080a9b8e2d8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/76/65/50258d8b7930e909ea2f5bd006a23d520a16765af13ab45bb3\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=fac24709b896617153f22c967685e96529fc18e08d3fe5f1295e27b814d307f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, sentencepiece, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-0.4.0 sentencepiece-0.1.94 tokenizers-0.9.4 transformers-4.1.1\n",
            "Collecting plotly==4.14.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/09/315462259ab7b60a3d4b7159233ed700733c87d889755bdc00a9fb46d692/plotly-4.14.1-py2.py3-none-any.whl (13.2MB)\n",
            "\u001b[K     |████████████████████████████████| 13.2MB 249kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly==4.14.1) (1.15.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.14.1) (1.3.3)\n",
            "Installing collected packages: plotly\n",
            "  Found existing installation: plotly 4.4.1\n",
            "    Uninstalling plotly-4.4.1:\n",
            "      Successfully uninstalled plotly-4.4.1\n",
            "Successfully installed plotly-4.14.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.4)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTFOUMjqvOKO"
      },
      "source": [
        "import torch\r\n",
        "import pandas as pd\r\n",
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUnYXmykyy-x"
      },
      "source": [
        "pd.set_option('max_colwidth', 800)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnX4GRR0wnXe",
        "outputId": "eda42b2d-3fd7-461d-a490-25811b4ce2fa"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print('using device: ', torch.cuda.get_device_name(device), flush=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using device:  Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3SLiW1dvVPz",
        "outputId": "00be0142-f7cb-4a42-9b4d-af1c2c1f9fe4"
      },
      "source": [
        "model = SentenceTransformer('paraphrase-distilroberta-base-v1')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 306M/306M [00:14<00:00, 21.4MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKDeSJ15v_wR"
      },
      "source": [
        "df = pd.read_csv('jokes_combined.csv', encoding='utf-8')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8bgojQiyDZO"
      },
      "source": [
        "# take a sample with 2 sentences from one category and 2 from another\r\n",
        "sample_a = df[df['category'] == 'Yo Mama'].sample(2)\r\n",
        "sample_b = df[df['category'] == 'Political'].sample(2)\r\n",
        "sample = pd.concat([sample_a, sample_b])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "LuTlbYf4ygBu",
        "outputId": "3eab4817-4dc9-4da9-bbbb-30f042c15cb5"
      },
      "source": [
        "sample"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>score</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>192778</th>\n",
              "      <td>Yo mama so dumb she burnt down the house using a cd burner</td>\n",
              "      <td>1.75</td>\n",
              "      <td>Yo Mama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192852</th>\n",
              "      <td>10 Yo Mama got so fat when she jump in the air, she got stuck.9 Yo Mama is soo  fat when she trip and fall she made the Grand Caryon.8 Yo Mama is soo fat when she step on the scale said \"Out of Order.\"7 Yo Mama is soo fat when she wore a red rain jacket, everyone yelled \"Hey Kool-Ade!\"6 Yo Mama is soo fat when she bungee jump she broke the bridge in half!5 Yo Mama is soo fat she wears a V.C.R. as a pager.4 Yo Mama is soo fat that the city gave her own zip code.3 Yo Mama is soo fat everyone at the baseball sadtium sat on her.2 Yo Mama is soo fat when she drop you off at school, she got a ticket for littering.1 Yo Mama is soo fat takes you a five mile walk around her.</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Yo Mama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194391</th>\n",
              "      <td>A man went to a doctor, and said he wanted to be able to get a job at the local Post Office, but unfortunately he was too smart. The doctor asked him his IQ, and when he gave a three-digit reply, the doctor told him that the procedure would have to involve the removal of over half of his brain.  The man insisted, and since the doctor just happened to have a brand new laser device which could zap just the right portions of brain tissue, the operation was planned.  The laser was hooked up to a computer which could monitor the man's declining IQ on a nice bright LED display.  The doctor threw the switch and the numbers began ticking off ... 95, 94, 93, ...  Suddenly the phone rang.  It was the doctor's wife.  They gabbed for a few minutes, the doctor forgetting completely about his patien...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>Political</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192728</th>\n",
              "      <td>An engineer, an accountant, a chemist and a bureaucrat were bragging about how smart their dogs are.The engineer called to his dog, \"T-square, do your stuff\". The dog took out paper and pen, and drew a circle, a squareand a triangle. Everyone agreed he was smart.The accountant called, \"Sliderule, do your stuff\". The pooch went to the kitchen, got a dozen cookies and made four stacks of three. Everyone was impressed.The chemist called, \"Beaker, do your stuff.\" The dog went to the fridge for a quart of milk, got a ten ounce glass and poured exactly eight ounces without spilling a drop. Everyone agreed that was great.The bureaucrat called, \"Coffee Break,do your stuff!\". Coffe Break ate the cookies, drank the milk, chewed the paper, claimed he injured his mouth doing so, filed a grievance ...</td>\n",
              "      <td>2.00</td>\n",
              "      <td>Political</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   text  ...   category\n",
              "192778                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Yo mama so dumb she burnt down the house using a cd burner  ...    Yo Mama\n",
              "192852                                                                                                                               10 Yo Mama got so fat when she jump in the air, she got stuck.9 Yo Mama is soo  fat when she trip and fall she made the Grand Caryon.8 Yo Mama is soo fat when she step on the scale said \"Out of Order.\"7 Yo Mama is soo fat when she wore a red rain jacket, everyone yelled \"Hey Kool-Ade!\"6 Yo Mama is soo fat when she bungee jump she broke the bridge in half!5 Yo Mama is soo fat she wears a V.C.R. as a pager.4 Yo Mama is soo fat that the city gave her own zip code.3 Yo Mama is soo fat everyone at the baseball sadtium sat on her.2 Yo Mama is soo fat when she drop you off at school, she got a ticket for littering.1 Yo Mama is soo fat takes you a five mile walk around her.  ...    Yo Mama\n",
              "194391  A man went to a doctor, and said he wanted to be able to get a job at the local Post Office, but unfortunately he was too smart. The doctor asked him his IQ, and when he gave a three-digit reply, the doctor told him that the procedure would have to involve the removal of over half of his brain.  The man insisted, and since the doctor just happened to have a brand new laser device which could zap just the right portions of brain tissue, the operation was planned.  The laser was hooked up to a computer which could monitor the man's declining IQ on a nice bright LED display.  The doctor threw the switch and the numbers began ticking off ... 95, 94, 93, ...  Suddenly the phone rang.  It was the doctor's wife.  They gabbed for a few minutes, the doctor forgetting completely about his patien...  ...  Political\n",
              "192728  An engineer, an accountant, a chemist and a bureaucrat were bragging about how smart their dogs are.The engineer called to his dog, \"T-square, do your stuff\". The dog took out paper and pen, and drew a circle, a squareand a triangle. Everyone agreed he was smart.The accountant called, \"Sliderule, do your stuff\". The pooch went to the kitchen, got a dozen cookies and made four stacks of three. Everyone was impressed.The chemist called, \"Beaker, do your stuff.\" The dog went to the fridge for a quart of milk, got a ten ounce glass and poured exactly eight ounces without spilling a drop. Everyone agreed that was great.The bureaucrat called, \"Coffee Break,do your stuff!\". Coffe Break ate the cookies, drank the milk, chewed the paper, claimed he injured his mouth doing so, filed a grievance ...  ...  Political\n",
              "\n",
              "[4 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2SZFn81zRID",
        "outputId": "abb8d4b9-f909-455e-bfe4-13e733f55682"
      },
      "source": [
        "sample.text.to_list()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Yo mama so dumb she burnt down the house using a cd burner',\n",
              " '10 Yo Mama got so fat when she jump in the air, she got stuck.9 Yo Mama is soo  fat when she trip and fall she made the Grand Caryon.8 Yo Mama is soo fat when she step on the scale said \"Out of Order.\"7 Yo Mama is soo fat when she wore a red rain jacket, everyone yelled \"Hey Kool-Ade!\"6 Yo Mama is soo fat when she bungee jump she broke the bridge in half!5 Yo Mama is soo fat she wears a V.C.R. as a pager.4 Yo Mama is soo fat that the city gave her own zip code.3 Yo Mama is soo fat everyone at the baseball sadtium sat on her.2 Yo Mama is soo fat when she drop you off at school, she got a ticket for littering.1 Yo Mama is soo fat takes you a five mile walk around her.',\n",
              " 'A man went to a doctor, and said he wanted to be able to get a job at the local Post Office, but unfortunately he was too smart. The doctor asked him his IQ, and when he gave a three-digit reply, the doctor told him that the procedure would have to involve the removal of over half of his brain.  The man insisted, and since the doctor just happened to have a brand new laser device which could zap just the right portions of brain tissue, the operation was planned.  The laser was hooked up to a computer which could monitor the man\\'s declining IQ on a nice bright LED display.  The doctor threw the switch and the numbers began ticking off ... 95, 94, 93, ...  Suddenly the phone rang.  It was the doctor\\'s wife.  They gabbed for a few minutes, the doctor forgetting completely about his patient.  When he hung up, he suddenly realized, and ran into the operating room, only to see the meter tick down ...  6, 5, 4, ...  He ran to the machine and threw the on/off switch, just as the laser was about to wipe out the last remnant of brain.  \"Holy moley!\" exclaimed the doctor, \"What have I done?  Speak to me. Say anything!\"  The man looked at him and said, \"I, George W. Bush, announce my candidacy for President of the United States...\"',\n",
              " 'An engineer, an accountant, a chemist and a bureaucrat were bragging about how smart their dogs are.The engineer called to his dog, \"T-square, do your stuff\". The dog took out paper and pen, and drew a circle, a squareand a triangle. Everyone agreed he was smart.The accountant called, \"Sliderule, do your stuff\". The pooch went to the kitchen, got a dozen cookies and made four stacks of three. Everyone was impressed.The chemist called, \"Beaker, do your stuff.\" The dog went to the fridge for a quart of milk, got a ten ounce glass and poured exactly eight ounces without spilling a drop. Everyone agreed that was great.The bureaucrat called, \"Coffee Break,do your stuff!\". Coffe Break ate the cookies, drank the milk, chewed the paper, claimed he injured his mouth doing so, filed a grievance for unsafe working conditions, put in for workers\\' compensation and took extended sick leave.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hTAvVI7y4h1"
      },
      "source": [
        "sample_embs = model.encode(sample.text.to_list(), convert_to_tensor=True)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-BMMRbuzgPu"
      },
      "source": [
        "sample_texts = sample.text.to_list()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ggbp5Oizv9c",
        "outputId": "f7994c25-9eb2-4a74-c948-10e211a8f77a"
      },
      "source": [
        "len(sample_embs[0])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW87bSYb1Qtj",
        "outputId": "6e76d135-937b-4093-f58a-1e8d6f308135"
      },
      "source": [
        "#Compute cosine-similarities for each sentence with each other sentence\r\n",
        "cosine_scores = util.pytorch_cos_sim(sample_embs, sample_embs)\r\n",
        "\r\n",
        "#Find the pairs with the highest cosine similarity scores\r\n",
        "pairs = []\r\n",
        "for i in range(len(cosine_scores)-1):\r\n",
        "    for j in range(i+1, len(cosine_scores)):\r\n",
        "        pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})\r\n",
        "\r\n",
        "#Sort scores in decreasing order\r\n",
        "pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\r\n",
        "\r\n",
        "for pair in pairs[0:10]:\r\n",
        "    i, j = pair['index']\r\n",
        "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sample_texts[i][:30], sample_texts[j][:30], pair['score']))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A man went to a doctor, and sa \t\t An engineer, an accountant, a  \t\t Score: 0.3656\n",
            "Yo mama so dumb she burnt down \t\t 10 Yo Mama got so fat when she \t\t Score: 0.2962\n",
            "Yo mama so dumb she burnt down \t\t An engineer, an accountant, a  \t\t Score: 0.2218\n",
            "10 Yo Mama got so fat when she \t\t An engineer, an accountant, a  \t\t Score: 0.1726\n",
            "Yo mama so dumb she burnt down \t\t A man went to a doctor, and sa \t\t Score: 0.1292\n",
            "10 Yo Mama got so fat when she \t\t A man went to a doctor, and sa \t\t Score: 0.0729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXrOEAD40Ltl",
        "outputId": "6a27493a-59a1-46f6-8d55-1f8a0fd966b6"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 204542 entries, 0 to 204541\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count   Dtype  \n",
            "---  ------    --------------   -----  \n",
            " 0   text      204541 non-null  object \n",
            " 1   score     194531 non-null  float64\n",
            " 2   category  13133 non-null   object \n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 4.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woxfG_7f0kO5"
      },
      "source": [
        "df = df.dropna(subset=['text'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN060mlw0yfH",
        "outputId": "a2091f78-44e2-4143-e23c-296a6e96cf3f"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(204541, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVY3PCpdzy9j"
      },
      "source": [
        "texts = df.text.to_list()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL_XoRPJ0CQ-",
        "outputId": "f70cf48e-6225-4f82-fdf2-86a1f16e6a75"
      },
      "source": [
        "%%time\r\n",
        "embs = model.encode(texts)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4min 36s, sys: 2min 19s, total: 6min 56s\n",
            "Wall time: 6min 56s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXDS10j84t6u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}